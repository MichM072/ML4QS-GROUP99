{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-20T15:40:12.458757Z",
     "start_time": "2025-06-20T15:40:12.452254Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "STUDENT = 'mmr497'\n",
    "DATA_PATH = Path('/local/data/mmr497')\n",
    "OUTLIERS_PATH = Path('./outliers2/')\n",
    "INTERMEDIATE_PATH = Path(f'{DATA_PATH}/intermediate_datafiles/')\n",
    "os.chdir(f'/home/{STUDENT}/')\n",
    "from util.VisualizeDataset import VisualizeDataset\n",
    "from Visualiser import Visualiser as Viz\n",
    "from util.util import ignore_actual_time, read_parquet, write_parquet\n",
    "from FeatureCreator import FeatureCreatorUpdated\n",
    "from DataLearningLoader import DataLearningLoader\n",
    "import pandas as pd\n",
    "from Chapter7.FeatureSelection import FeatureSelectionClassification\n",
    "from Chapter7.LearningAlgorithms import ClassificationAlgorithms\n",
    "from AlteredAlgorithms import AlteredAlgorithmsClassifier\n",
    "from Chapter7.Evaluation import ClassificationEvaluation\n",
    "import numpy as np\n",
    "from CustomPipeline import PreConfiguredPipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:01:34.877296Z",
     "start_time": "2025-06-20T15:01:34.873940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing parameters\n",
    "feature_selection = True"
   ],
   "id": "f77c07c7a6489849",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:25:21.600560Z",
     "start_time": "2025-06-20T15:25:21.596873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EasyViz = Viz()\n",
    "DataViz = VisualizeDataset('ML2.ipynb')"
   ],
   "id": "ab41a3b45034fc7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:01:35.054436Z",
     "start_time": "2025-06-20T15:01:35.051763Z"
    }
   },
   "cell_type": "code",
   "source": "# cleaned_dataset = read_parquet(INTERMEDIATE_PATH / 'ML4QS_imputed_results.parquet')",
   "id": "c7a2d7c369deabf5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:01:35.151195Z",
     "start_time": "2025-06-20T15:01:35.148455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# instance_mask = cleaned_dataset.id == 1\n",
    "# col = 'location_phone_Velocity'\n",
    "# print(cleaned_dataset.loc[instance_mask, col].isna().sum() / len(cleaned_dataset.loc[instance_mask, col]))\n",
    "# if cleaned_dataset.loc[instance_mask, col].isna().all():\n",
    "#     print('All values are NaN for instance {}.'.format(cleaned_dataset.loc[instance_mask, 'id'].values[0]))"
   ],
   "id": "582c66427d33a87b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:01:35.217789Z",
     "start_time": "2025-06-20T15:01:35.215244Z"
    }
   },
   "cell_type": "code",
   "source": "# cleaned_dataset.dtypes",
   "id": "778eab95ad750ec3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:01:35.280105Z",
     "start_time": "2025-06-20T15:01:35.277557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test_df = read_parquet(INTERMEDIATE_PATH / 'non_fourier_features.parquet')\n",
    "# nan_counts = test_df.isna().sum()\n",
    "# nan_cols = nan_counts[nan_counts > 0]\n",
    "# print(nan_cols)"
   ],
   "id": "79506c1f3e31a12f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:01:35.340930Z",
     "start_time": "2025-06-20T15:01:35.338411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# fcr = FeatureCreatorUpdated(INTERMEDIATE_PATH)\n",
    "# DLL = DataLearningLoader(df_path=INTERMEDIATE_PATH, output_dir=INTERMEDIATE_PATH, verbose=False)"
   ],
   "id": "da58cc156401497e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:01:35.418187Z",
     "start_time": "2025-06-20T15:01:35.415887Z"
    }
   },
   "cell_type": "code",
   "source": "# feature_df = fcr.create_features(cleaned_dataset, overwrite=True)",
   "id": "da3853d1023a23c9",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:01:35.481935Z",
     "start_time": "2025-06-20T15:01:35.479647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# nan_counts = feature_df.isna().sum()\n",
    "# nan_cols = nan_counts[nan_counts > 0]\n",
    "# print(nan_cols)"
   ],
   "id": "250cceec29a0ccf1",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:01:35.543392Z",
     "start_time": "2025-06-20T15:01:35.540903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Stupid fix! Only temporary! MUST REMOVE\n",
    "# def remove_nan_cols(df):\n",
    "#     df_fs = df.copy()\n",
    "#     col_before = df_fs.columns\n",
    "#     nan_counts = df_fs.isna().sum()\n",
    "#     nan_cols = nan_counts[nan_counts > 0]\n",
    "#     df_fs = df_fs.drop(nan_cols.index, axis=1)\n",
    "#     col_after = df_fs.columns\n",
    "#     print('Removed columns: ', [col for col in col_before if col not in col_after])\n",
    "#     return df_fs\n",
    "#\n",
    "# filtered_feature_df = remove_nan_cols(feature_df)"
   ],
   "id": "be1319f05bed9e25",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:01:35.671858Z",
     "start_time": "2025-06-20T15:01:35.669552Z"
    }
   },
   "cell_type": "code",
   "source": "# X_train, X_test, y_train, y_test = DLL.prepare_data(filtered_feature_df)",
   "id": "b41ec7b7e099ca5b",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:25:24.346681Z",
     "start_time": "2025-06-20T15:25:24.082555Z"
    }
   },
   "cell_type": "code",
   "source": "intermediate_df = read_parquet(INTERMEDIATE_PATH / 'ML4QS_combined_results_example.parquet')",
   "id": "95c71275a9644ce2",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:25:25.251814Z",
     "start_time": "2025-06-20T15:25:25.244746Z"
    }
   },
   "cell_type": "code",
   "source": "intermediate_df.dtypes",
   "id": "fed6173d31ccd4e6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                      int64\n",
       "acc_phone_X                           float64\n",
       "acc_phone_Y                           float64\n",
       "acc_phone_Z                           float64\n",
       "lin_acc_phone_X                       float64\n",
       "lin_acc_phone_Y                       float64\n",
       "lin_acc_phone_Z                       float64\n",
       "gyr_phone_X                           float64\n",
       "gyr_phone_Y                           float64\n",
       "gyr_phone_Z                           float64\n",
       "location_phone_Latitude               float64\n",
       "location_phone_Longitude              float64\n",
       "location_phone_Height                 float64\n",
       "location_phone_Velocity               float64\n",
       "location_phone_Direction              float64\n",
       "location_phone_Horizontal Accuracy    float64\n",
       "location_phone_Vertical Accuracy      float64\n",
       "mag_phone_X                           float64\n",
       "mag_phone_Y                           float64\n",
       "mag_phone_Z                           float64\n",
       "proximity_phone_Distance              float64\n",
       "labeltram                               int64\n",
       "labeltrain                              int64\n",
       "labelwalking                            int64\n",
       "labelmetro                              int64\n",
       "labelbus                                int64\n",
       "labelcar                                int64\n",
       "labelbike                               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:25:27.753860Z",
     "start_time": "2025-06-20T15:25:27.749875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def write_splitted_data(data):\n",
    "\n",
    "    if len(data[0]) == 1:\n",
    "        print(\"Expecting format: (data, name) ... continuing.\")\n",
    "\n",
    "    for data, name in data:\n",
    "        try:\n",
    "            write_parquet(data, INTERMEDIATE_PATH / f'{name}_postpipe.parquet')\n",
    "        except:\n",
    "            print(\"Can't write parquet file for \", name, \" ... continuing.\")"
   ],
   "id": "179e7983bbcf97e3",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:26:40.319309Z",
     "start_time": "2025-06-20T15:26:09.616626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipe_NF = PreConfiguredPipeline(intermediate_path=INTERMEDIATE_PATH, include_fourier=False)\n",
    "X_train, X_test, y_train, y_test = pipe_NF.fit_transform(intermediate_df, verbose=True, overwrite=True, pipe_name=\"NF\")"
   ],
   "id": "b372d9d02daf8624",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Removing bad sensors...\n",
      "[INFO] Removing bad sensors...\n",
      "[INFO] Splitting data into train and test sets...\n",
      "[INFO] Splitting data into train and test sets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING THIS FEATURE CREATOR USE NO FOURIER FEATURES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Starting preprocessing pipeline...\n",
      "[INFO] Starting preprocessing pipeline...\n",
      "[INFO] Preprocessing NF_X_train...\n",
      "[INFO] Preprocessing NF_X_train...\n",
      "[INFO] Checking for outliers...\n",
      "[INFO] Checking for outliers...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bike: Only 2 sessions - 1 train, 1 test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Ensuring correct data types...\n",
      "[INFO] Ensuring correct data types...\n",
      "[INFO] Imputing missing values...\n",
      "[INFO] Imputing missing values...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No observed values for location_phone_Direction for vehicle type labeltrain.\n",
      "No observed values for location_phone_Direction for vehicle type labeltrain.\n",
      "No observed values for location_phone_Direction for vehicle type labeltrain.\n",
      "No observed values for location_phone_Direction for vehicle type labeltrain.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Creating features...\n",
      "[INFO] Creating features...\n",
      "[INFO] Dropping any direction data!\n",
      "[INFO] Dropping any direction data!\n",
      "[INFO] Cleaning data...\n",
      "[INFO] Cleaning data...\n",
      "[INFO] Preprocessing NF_X_train complete!\n",
      "[INFO] Preprocessing NF_X_train complete!\n",
      "[INFO] Preprocessing NF_X_test...\n",
      "[INFO] Preprocessing NF_X_test...\n",
      "[INFO] Checking for outliers...\n",
      "[INFO] Checking for outliers...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully written to parquet file at  /local/data/mmr497/intermediate_datafiles/NF_X_train.parquet \n",
      "\n",
      "Cleaning data...\n",
      "Cleaning features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Ensuring correct data types...\n",
      "[INFO] Ensuring correct data types...\n",
      "[INFO] Imputing missing values...\n",
      "[INFO] Imputing missing values...\n",
      "[INFO] Creating features...\n",
      "[INFO] Creating features...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No observed values for location_phone_Velocity for vehicle type labeltrain.\n",
      "No observed values for location_phone_Direction for vehicle type labeltrain.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Dropping any direction data!\n",
      "[INFO] Dropping any direction data!\n",
      "[INFO] Cleaning data...\n",
      "[INFO] Cleaning data...\n",
      "[INFO] Preprocessing NF_X_test complete!\n",
      "[INFO] Preprocessing NF_X_test complete!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully written to parquet file at  /local/data/mmr497/intermediate_datafiles/NF_X_test.parquet \n",
      "\n",
      "Cleaning data...\n",
      "Cleaning features...\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:27:47.736765Z",
     "start_time": "2025-06-20T15:27:47.343626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nf_data = [(X_train, \"X_train_NF\"), (X_test, \"X_test_NF\"), (y_train, \"y_train_NF\"), (y_test, \"y_test_NF\")]\n",
    "write_splitted_data(nf_data)"
   ],
   "id": "a08a476e78d4d67c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully written to parquet file at  /local/data/mmr497/intermediate_datafiles/X_train_NF_postpipe.parquet \n",
      "\n",
      "Successfully written to parquet file at  /local/data/mmr497/intermediate_datafiles/X_test_NF_postpipe.parquet \n",
      "\n",
      "Successfully written to parquet file at  /local/data/mmr497/intermediate_datafiles/y_train_NF_postpipe.parquet \n",
      "\n",
      "Successfully written to parquet file at  /local/data/mmr497/intermediate_datafiles/y_test_NF_postpipe.parquet \n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:30:58.518766Z",
     "start_time": "2025-06-20T15:30:38.774130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipe = PreConfiguredPipeline(intermediate_path=INTERMEDIATE_PATH)\n",
    "X_train, X_test, y_train, y_test = pipe.fit_transform(intermediate_df, verbose=True, overwrite=False)"
   ],
   "id": "a3df952e04d74a40",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Removing bad sensors...\n",
      "[INFO] Removing bad sensors...\n",
      "[INFO] Removing bad sensors...\n",
      "[INFO] Splitting data into train and test sets...\n",
      "[INFO] Splitting data into train and test sets...\n",
      "[INFO] Splitting data into train and test sets...\n",
      "[INFO] Starting preprocessing pipeline...\n",
      "[INFO] Starting preprocessing pipeline...\n",
      "[INFO] Starting preprocessing pipeline...\n",
      "[INFO] Preprocessing X_train...\n",
      "[INFO] Preprocessing X_train...\n",
      "[INFO] Preprocessing X_train...\n",
      "[INFO] Checking for outliers...\n",
      "[INFO] Checking for outliers...\n",
      "[INFO] Checking for outliers...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bike: Only 2 sessions - 1 train, 1 test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Ensuring correct data types...\n",
      "[INFO] Ensuring correct data types...\n",
      "[INFO] Ensuring correct data types...\n",
      "[INFO] Imputing missing values...\n",
      "[INFO] Imputing missing values...\n",
      "[INFO] Imputing missing values...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No observed values for location_phone_Direction for vehicle type labeltrain.\n",
      "No observed values for location_phone_Direction for vehicle type labeltrain.\n",
      "No observed values for location_phone_Direction for vehicle type labeltrain.\n",
      "No observed values for location_phone_Direction for vehicle type labeltrain.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Creating features...\n",
      "[INFO] Creating features...\n",
      "[INFO] Creating features...\n",
      "[INFO] Dropping any direction data!\n",
      "[INFO] Dropping any direction data!\n",
      "[INFO] Dropping any direction data!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined features already exist at /local/data/mmr497/intermediate_datafiles/X_train_combined_features.parquet\n",
      "Loaded combined features from /local/data/mmr497/intermediate_datafiles/X_train_combined_features.parquet\n",
      "If this was not intended, rerun create_features with overwrite=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Cleaning data...\n",
      "[INFO] Cleaning data...\n",
      "[INFO] Cleaning data...\n",
      "[INFO] Preprocessing X_train complete!\n",
      "[INFO] Preprocessing X_train complete!\n",
      "[INFO] Preprocessing X_train complete!\n",
      "[INFO] Preprocessing X_test...\n",
      "[INFO] Preprocessing X_test...\n",
      "[INFO] Preprocessing X_test...\n",
      "[INFO] Checking for outliers...\n",
      "[INFO] Checking for outliers...\n",
      "[INFO] Checking for outliers...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning data...\n",
      "Cleaning features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Ensuring correct data types...\n",
      "[INFO] Ensuring correct data types...\n",
      "[INFO] Ensuring correct data types...\n",
      "[INFO] Imputing missing values...\n",
      "[INFO] Imputing missing values...\n",
      "[INFO] Imputing missing values...\n",
      "[INFO] Creating features...\n",
      "[INFO] Creating features...\n",
      "[INFO] Creating features...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No observed values for location_phone_Velocity for vehicle type labeltrain.\n",
      "No observed values for location_phone_Direction for vehicle type labeltrain.\n",
      "Combined features already exist at /local/data/mmr497/intermediate_datafiles/X_test_combined_features.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Dropping any direction data!\n",
      "[INFO] Dropping any direction data!\n",
      "[INFO] Dropping any direction data!\n",
      "[INFO] Cleaning data...\n",
      "[INFO] Cleaning data...\n",
      "[INFO] Cleaning data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded combined features from /local/data/mmr497/intermediate_datafiles/X_test_combined_features.parquet\n",
      "If this was not intended, rerun create_features with overwrite=True\n",
      "Cleaning data...\n",
      "Cleaning features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Preprocessing X_test complete!\n",
      "[INFO] Preprocessing X_test complete!\n",
      "[INFO] Preprocessing X_test complete!\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# pipe = PreConfiguredPipeline(intermediate_path=INTERMEDIATE_PATH)\n",
    "# X_train, X_test, y_train, y_test = pipe.fit_transform(intermediate_df, verbose=True, overwrite=False)"
   ],
   "id": "a7f228f42ed73d6f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:36:00.498234Z",
     "start_time": "2025-06-20T15:36:00.490671Z"
    }
   },
   "cell_type": "code",
   "source": "y_test",
   "id": "d82f28b2678dd961",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "1970-01-01 00:54:19.750    metro\n",
       "1970-01-01 00:54:20.000    metro\n",
       "1970-01-01 00:54:20.250    metro\n",
       "1970-01-01 00:54:20.500    metro\n",
       "1970-01-01 00:54:20.750    metro\n",
       "                           ...  \n",
       "1970-01-01 03:30:08.000    train\n",
       "1970-01-01 03:30:08.250    train\n",
       "1970-01-01 03:30:08.500    train\n",
       "1970-01-01 03:30:08.750    train\n",
       "1970-01-01 03:30:09.000    train\n",
       "Name: transport_mode, Length: 20479, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# write_splitted_data([(X_train, \"X_train\"), (X_test, \"X_test\"), (y_train, \"y_train\"), (y_test, \"y_test\")])",
   "id": "db7c27dfe428af6d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:01:59.169600Z",
     "start_time": "2025-06-20T15:01:59.163608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Optional for testing\n",
    "\n",
    "def remove_problem_cols(df):\n",
    "    # This is for testing purposes, stupid fix!\n",
    "    df_fs = df.copy()\n",
    "    col_before = df_fs.columns\n",
    "    df_fs = df_fs.select_dtypes(include=[np.number], exclude=['timedelta64[ns]'])\n",
    "    col_after = df_fs.columns\n",
    "    print('Removed columns: ', [col for col in col_before if col not in col_after])\n",
    "    return df_fs\n",
    "\n",
    "def feature_selection(X_train, X_test, y_train, y_test):\n",
    "    fs = FeatureSelectionClassification()\n",
    "\n",
    "    N_FORWARD_SELECTION = 50\n",
    "\n",
    "    X_train_fs = remove_problem_cols(X_train)\n",
    "    X_test_fs = remove_problem_cols(X_test)\n",
    "\n",
    "    features, ordered_features, ordered_scores = fs.forward_selection(N_FORWARD_SELECTION,\n",
    "                                                                          X_train_fs,\n",
    "                                                                          X_test_fs,\n",
    "                                                                          y_train,\n",
    "                                                                          y_test,\n",
    "                                                                          gridsearch=True)\n",
    "\n",
    "    return features, ordered_features, ordered_scores\n",
    "\n",
    "        # DataViz.plot_xy(x=[range(1, N_FORWARD_SELECTION+1)], y=[ordered_scores],\n",
    "        #             xlabel='number of features', ylabel='accuracy')"
   ],
   "id": "d52d524827b9da07",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:01:59.351837Z",
     "start_time": "2025-06-20T15:01:59.348869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EvaluationContainer:\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name"
   ],
   "id": "d0808f98578101ac",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:03:43.636710Z",
     "start_time": "2025-06-20T15:03:43.574202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# nan_counts = X_test_fs.isna().sum()\n",
    "# nan_cols = nan_counts[nan_counts > 0]\n",
    "# print(nan_cols)"
   ],
   "id": "714d3488ac717c0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location_phone_Velocity           4522\n",
      "location_phone_Velocity_mean      4522\n",
      "location_phone_Velocity_median    4522\n",
      "location_phone_Velocity_min       4522\n",
      "location_phone_Velocity_max       4522\n",
      "session_avg_velocity              4522\n",
      "session_velocity_std              4522\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:48:23.582750Z",
     "start_time": "2025-06-20T15:48:23.576409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_class_distribution(data, title: str = 'Class distribution'):\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        data['transport_mode'] = data['transport_mode'].astype('string')\n",
    "        print(data['transport_mode'].dtypes)\n",
    "        sns.countplot(x='transport_mode', data=data)\n",
    "        plt.xlabel('transport_mode')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "    elif isinstance(data, pd.Series):\n",
    "        data = pd.Series(data)\n",
    "        sns.countplot(x=data)\n",
    "        plt.xlabel('Label')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title(title)\n",
    "        plt.show()"
   ],
   "id": "41cca3b3a74eb32e",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:46:13.705742Z",
     "start_time": "2025-06-20T15:46:13.700893Z"
    }
   },
   "cell_type": "code",
   "source": "y_test_test = y_test.reset_index()",
   "id": "ce255db4b98a776c",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:45:40.201783Z",
     "start_time": "2025-06-20T15:45:40.196276Z"
    }
   },
   "cell_type": "code",
   "source": "y_test_test['transport_mode'].dtypes",
   "id": "4038ecce391353c8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:48:26.543083Z",
     "start_time": "2025-06-20T15:48:25.706152Z"
    }
   },
   "cell_type": "code",
   "source": "plot_class_distribution(y_test_test)",
   "id": "34224b34dc89b1c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_685906/105364256.py\", line 1, in <module>\n",
      "    plot_class_distribution(y_test_test)\n",
      "  File \"/tmp/ipykernel_685906/3193065897.py\", line 5, in plot_class_distribution\n",
      "    sns.countplot(x='transport_mode', data=data)\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/seaborn/categorical.py\", line 2631, in countplot\n",
      "    p = _CategoricalAggPlotter(\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/seaborn/categorical.py\", line 67, in __init__\n",
      "    super().__init__(data=data, variables=variables)\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/seaborn/_base.py\", line 634, in __init__\n",
      "    self.assign_variables(data, variables)\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/seaborn/_base.py\", line 679, in assign_variables\n",
      "    plot_data = PlotData(data, variables)\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/seaborn/_core/data.py\", line 58, in __init__\n",
      "    frame, names, ids = self._assign_variables(data, variables)\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/seaborn/_core/data.py\", line 265, in _assign_variables\n",
      "    frame = pd.DataFrame(plot_data)\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/pandas/core/frame.py\", line 435, in __init__\n",
      "    5  baz           3  baz            7\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/pandas/core/internals/construction.py\", line 254, in init_dict\n",
      "    if not len(values) and columns is not None and len(columns):\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/pandas/core/internals/construction.py\", line 69, in arrays_to_mgr\n",
      "    DatetimeIndex,\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/pandas/core/internals/construction.py\", line 322, in _homogenize\n",
      "    if dtype is not None and not is_dtype_equal(values.dtype, dtype):\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/pandas/core/construction.py\", line 465, in sanitize_array\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/pandas/core/dtypes/cast.py\", line 1452, in construct_1d_arraylike_from_scalar\n",
      "    # => object\n",
      "TypeError: Cannot interpret '<attribute 'dtype' of 'numpy.generic' objects>' as a data type\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1396, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1287, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1140, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1055, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 955, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 778, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/local/data/mmr497/.conda/envs/ML4QS/lib/python3.8/site-packages/executing/executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:06:03.738166Z",
     "start_time": "2025-06-20T15:05:57.703129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup model\n",
    "CA = ClassificationAlgorithms()\n",
    "alt_CA = AlteredAlgorithmsClassifier()\n",
    "\n",
    "X_train_fs = remove_problem_cols(X_train)\n",
    "X_test_fs = remove_problem_cols(X_test)\n",
    "\n",
    "# TODO: Delete after testing\n",
    "\n",
    "test_X_test = X_test_fs.copy()\n",
    "test_X_test = test_X_test.fillna(0)\n",
    "\n",
    "nb_train_y, nb_test_y, nb_train_prob_y, nb_test_prob_y = alt_CA.naive_bayes(\n",
    "        X_train_fs, y_train, test_X_test\n",
    "    )\n"
   ],
   "id": "63815df1dc54f370",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed columns:  ['original_time', 'time_diff', 'shifted_time']\n",
      "Removed columns:  ['original_time', 'time_diff', 'shifted_time']\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T15:08:20.006049Z",
     "start_time": "2025-06-20T15:08:19.553894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate models\n",
    "evalCA = ClassificationEvaluation()\n",
    "\n",
    "evaluations = {}\n",
    "\n",
    "print(classification_report(y_test, nb_test_y, zero_division=0))\n",
    "print(confusion_matrix(y_test, nb_test_y))"
   ],
   "id": "af6575e99fcac879",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        bike       0.00      0.00      0.00      2423\n",
      "         bus       0.00      0.00      0.00      1915\n",
      "         car       0.00      0.00      0.00      4136\n",
      "       metro       0.33      0.17      0.23      3061\n",
      "       train       0.35      1.00      0.52      4522\n",
      "        tram       0.00      0.00      0.00       808\n",
      "     walking       0.60      1.00      0.75      3614\n",
      "\n",
      "    accuracy                           0.42     20479\n",
      "   macro avg       0.18      0.31      0.21     20479\n",
      "weighted avg       0.23      0.42      0.28     20479\n",
      "\n",
      "[[   0    0    0    0    0    0 2423]\n",
      " [   0    0    0    0 1915    0    0]\n",
      " [   0    0    0 1082 3054    0    0]\n",
      " [   0    0    0  533 2528    0    0]\n",
      " [   0    0    0    0 4522    0    0]\n",
      " [   0    0    0    0  808    0    0]\n",
      " [   0    0    0    0    0    0 3614]]\n"
     ]
    }
   ],
   "execution_count": 29
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
